Skoltech NLA project: Optimal Layer-wise Decomposition
===================================

## What is this project about?

In this project, we conducted experiments on the efficient compression of neural network layers. We tried to achieve efficiency on each local layer as well as the whole network with minimal loss of prediction accuracy.

Based on theory provided by article: "Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition" by Lucas Liebenwein,  Alaa Maalouf, Oren Gal, Dan Feldman, Daniela Rus

![]([https://drive.google.com/file/d/1cyyh833ZKAy-fNU7i93Kh-Q57QibSHai/view?usp=sharing])

## Quickstart

Cloning the repository with all required submodules:

    git clone https://github.com/AlicePH/NLA-project
    cd NLA-project




